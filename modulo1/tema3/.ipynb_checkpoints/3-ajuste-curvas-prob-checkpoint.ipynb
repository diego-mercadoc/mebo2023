{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de curvas desde una perspectiva probabilística\n",
    "\n",
    "![BLR](https://upload.wikimedia.org/wikipedia/commons/e/ed/Residuals_for_Linear_Regression_Fit.png)\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Recordar el ajuste de curvas polinomiales.\n",
    "> - Entender el fenómeno de overfitting en casos prácticos.\n",
    "> - Explicar los mínimos cuadrados ordinaros mediante el principio de máxima verosimilitud.\n",
    "\n",
    "> **Referencias:**\n",
    "> \n",
    "> - Pattern Recognition and Machine Learning, by Christopher M. Bishop - Cap. 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Al día de hoy todos debemos haber ajustado una línea recta (plano, o hiperplano) de la forma\n",
    "\n",
    "$$\n",
    "f(x) = w_1 x^{(1)} + w_2 x^{(2)} + \\dots + w_d x^{(d)} = x^T w \\qquad \\text{(generalmente el primer término es de bias $x^{(1)} = 1$)}\n",
    "$$\n",
    "\n",
    "a un conjunto de puntos $\\{(x_i, y_i)\\}_{i=1}^{N}$, con $x_i\\in\\mathbb{R}^{d}$ y $y_i\\in\\mathbb{R}$, y parámetros $w\\in\\mathbb{R}^{d}$. Esto normalmente se hace bajo el enfoque de mínimos cuadrados, es decir:\n",
    "\n",
    "$$\n",
    "\\hat{w} = \\arg \\min_{w} ||y - Xw||^2,\n",
    "$$\n",
    "  \n",
    "donde \n",
    " \n",
    "$$\n",
    "  X = \\left[\\begin{array}{ccc}\n",
    "  - & x_1^T  & - \\\\\n",
    "  - & x_2^T  & - \\\\\n",
    "    & \\vdots &   \\\\\n",
    "  - & x_N^T  & - \\\\\n",
    "  \\end{array}\\right] \\in \\mathbb{R}^{N \\times d}, \\qquad y = \\left[\\begin{array}{ccc}\n",
    "  y_1 \\\\\n",
    "  y_2 \\\\\n",
    "  \\vdots \\\\\n",
    "  y_N \\\\\n",
    "  \\end{array}\\right] \\in \\mathbb{R}^{N}.\n",
    "$$\n",
    "\n",
    "Este modelo es probablemente el más simple, ya que involucra únicamente una combinación lineal de las variables de entrada. Al ser lineal, es un modelo bastante limitado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, podemos extender este tipo de modelos para considerar combinaciones lineales de funciones no-lineales de las variables de entrada, de la forma:\n",
    "\n",
    "$$\n",
    "f(x) = w_1 \\phi_1(x) + w_2 \\phi_2(x) + \\dots + w_d \\phi_d(x) = \\phi(x)^T w \\qquad \\text{(generalmente el primer término es de bias $\\phi_1(x) = 1$)},\n",
    "$$\n",
    "\n",
    "donde $\\phi = \\left[\\phi_1, \\phi_2, \\dots, \\phi_d\\right] \\in \\mathbb{R}^d$. De esta manera podemos modelar relaciones mucho más complejas. Este tipo de funciones las seguimos llamando **lineales** puesto que lo son respecto a los parámetros $w$.\n",
    "\n",
    "En este caso, los parámetros los encontramos como\n",
    "\n",
    "$$\n",
    "\\hat{w} = \\arg \\min_{w} ||y - \\Phi w||^2,\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "\\Phi = \\left[\n",
    "    \\begin{array}{ccc}\n",
    "    - & \\phi(x_1)^T  & - \\\\\n",
    "    - & \\phi(x_2)^T  & - \\\\\n",
    "      & \\vdots       &   \\\\\n",
    "    - & \\phi(x_N)^T  & - \\\\\n",
    "    \\end{array}\n",
    "\\right] \\in \\mathbb{R}^{N \\times d}.\n",
    "$$\n",
    "\n",
    "Una elección común de las funciones $\\phi_j(x) = x^{j-1}$, para lograr funciones polinomiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos ficticios\n",
    "N = 20\n",
    "x = np.linspace(0, 1, N)\n",
    "y = np.sin(2 * np.pi * x) + 0.3 * np.random.normal(size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de los datos\n",
    "plt.plot(x, y, '+', ms=5, label='Datos')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de curvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.model_selection.train_test_split\n",
    "\n",
    "# sklearn.preprocessing.PolynomialFeatures\n",
    "\n",
    "# sklearn.linear_model.LinearRegression\n",
    "\n",
    "# sklearn.preprocessing.StandardScaler\n",
    "\n",
    "# sklearn.pipeline.Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grado 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grado 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo lidiar con el overfitting? \n",
    "\n",
    "#### 1. Regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin regularizacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Más datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos ficticios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sobre datos de prueba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distribución normal\n",
    "\n",
    "Antes de entrar en detalles repasemos un poco la distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Distribución normal univariada\n",
    "\n",
    "Se dice que una VA distribuye normal si su función de densidad de probabilidad es:\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left\\{-\\frac{(x - \\mu)^2}{2 \\sigma^2}\\right\\}\n",
    "$$\n",
    "\n",
    "con parámetros $\\mu \\in \\mathbb{R}$: media de la VA X, y $\\sigma^2 \\in \\mathbb{R}_{\\geq0}$: varianza de la VA X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.** Demostrar que:\n",
    "\n",
    "1. \n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} \\mathcal{N}(x|\\mu, \\sigma^2) = 1.\n",
    "$$\n",
    "\n",
    "2. \n",
    "$$\n",
    "\\mu = \\arg \\max_{x} \\mathcal{N}(x|\\mu, \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo luce esta densidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar scipy.stats\n",
    "from scipy import stats\n",
    "# Importar numpy\n",
    "import numpy as np\n",
    "# Importar matplitlib.pyplot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tres VA normales\n",
    "X = stats.norm(loc=0, scale=1)\n",
    "Y = stats.norm(loc=1, scale=1)\n",
    "Z = stats.norm(loc=0, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector x para graficar\n",
    "x = np.linspace(-10, 10, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "plt.plot(x, X.pdf(x), label=r'N(x|0,1)')\n",
    "plt.plot(x, Y.pdf(x), label=r'N(x|1,1)')\n",
    "plt.xlabel('$x$')\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, X.pdf(x), label=r'N(x|0,1)')\n",
    "plt.plot(x, Z.pdf(x), label=r'N(x|0,3^2)')\n",
    "plt.xlabel('$x$')\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Desde una perspectiva probabilística\n",
    "\n",
    "Para modelar la incertidumbre en este tipo de relaciones, podemos suponer que el ruido aditivo sigue una densidad Gaussiana:\n",
    "\n",
    "$$\n",
    "y = \\phi(x)^T w + \\epsilon,\n",
    "$$\n",
    "\n",
    "con $\\epsilon \\sim \\mathcal{N}(0, \\beta^{-1})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera que\n",
    "\n",
    "$$\n",
    "p(y | x, w) = \\mathcal{N}(y | \\phi(x)^T w, \\beta^{-1}),\n",
    "$$\n",
    "\n",
    "es decir, con la relación $\\phi(x)^T w$ modela el valor esperado de la variable de salida $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de parámetros: Máxima verosimilitud\n",
    "\n",
    "Para estimar los parámetros, escribimos entonces la función de verosimilitud:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w) = p(y | X, w) = \\prod_{i=1}^{N} \\mathcal{N}(y_i | \\phi(x_i)^T w, \\beta^{-1}).\n",
    "$$\n",
    "\n",
    "Por tanto, la log verosimilitud es:\n",
    "\n",
    "\\begin{align}\n",
    "l(w) & = \\log \\prod_{i=1}^{N} \\mathcal{N}(y_i | \\phi(x_i)^T w, \\beta^{-1}) \\\\\n",
    "     & = \\sum_{i=1}^{N} \\log\\mathcal{N}(y_i | \\phi(x_i)^T w, \\beta^{-1}) \\\\\n",
    "     & = \\frac{N}{2}\\log\\beta - \\frac{N}{2}\\log(2 \\pi) - \\frac{\\beta}{2} \\sum_{i=1}^{N} (y_i - \\phi(x_i)^T w)^2 \\\\\n",
    "     & = \\frac{N}{2}\\log\\beta - \\frac{N}{2}\\log(2 \\pi) - \\frac{\\beta}{2} \\left|\\left|y - \\Phi w\\right|\\right|^2,\n",
    "\\end{align}\n",
    "\n",
    "donde:\n",
    "\n",
    "$$\n",
    "\\Phi = \\left[\n",
    "    \\begin{array}{ccc}\n",
    "    - & \\phi(x_1)^T  & - \\\\\n",
    "    - & \\phi(x_2)^T  & - \\\\\n",
    "      & \\vdots       &   \\\\\n",
    "    - & \\phi(x_N)^T  & - \\\\\n",
    "    \\end{array}\n",
    "\\right] \\in \\mathbb{R}^{N \\times d}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, usando el principio de máxima verosimilitud, obtenemos que:\n",
    "\n",
    "$$\n",
    "\\hat{w}_{MLE} = \\arg \\max_{w} l(w) = \\arg \\min_{w} \\left|\\left|y - \\Phi w\\right|\\right|^2,\n",
    "$$\n",
    "\n",
    "justo como en mínimos cuadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la estimación de parámetros por máxima verosimilitud, explica nuestra intuición detrás de mínimos cuadrados.\n",
    "\n",
    "Además, **una vez más concluimos que el enfoque de máxima verosimilitud nos puede traer problemas de overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
