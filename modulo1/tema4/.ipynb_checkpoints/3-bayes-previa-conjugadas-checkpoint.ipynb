{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema de Bayes, distribuciones previas y previas conjugadas\n",
    "\n",
    "![bayes](https://upload.wikimedia.org/wikipedia/commons/1/18/Bayes%27_Theorem_MMB_01.jpg)\n",
    "\n",
    "> Justo como ilustra la imagen de arriba, dadas dos VA $A$ y $B$, el Teorema de Bayes se puede escribir como:\n",
    "> \n",
    "> $$\n",
    "  P(A | B) = \\frac{P(B | A) P(A)}{P(B)}\n",
    "  $$\n",
    "  \n",
    "> En este notebook recapitularemos qué significa cada uno de esos elementos, estudiaremos porqué es complejo el cálculo exacto de la distribución posterior, y veremos un método analítico para hacer este cálculo exacto.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Explicar porqué el cálculo exacto de la distribución posterior es una tarea intratable en muchas ocasiones.\n",
    "> - Principio de Maximum Aposteriori (MAP).\n",
    "> - Comprender el concepto de distribución previa conjugada.\n",
    "\n",
    "> **Referencias:**\n",
    "> - Bayesian Methods for Machine Learning course, HSE University, Coursera.\n",
    "> - Statistical Rethinking, Richard McElreath, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Teorema de Bayes\n",
    "\n",
    "Como ya vimos, el enfoque Bayesiano considera que los parámetros $\\theta$ son los que se consideran aleatorios, y los datos $X$ están fijos como evidencia.\n",
    "\n",
    "En ese sentido, nos interesa modelar la distribución de los parámetros dada la evidencia que estamos observando $P(\\theta | X)$, lo cual, por el Teorema de Bayes podemos escribir como:\n",
    "\n",
    "$$\n",
    "P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)},\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $P(\\theta | X)$ se conoce como **distribución posterior** (en inglés *posterior*). La posterior nos dice la probabilidad de los parámetros después de haber observado los datos.\n",
    "- $P(X | \\theta)$ se conoce como **función de verosimilitud** (en inglés *likelihood*). La verosimilitud nos dice que tan bien los parámetros explican los datos.\n",
    "- $P(\\theta)$ se conoce como **distribución previa** (en inglés *prior*). En la previa, incluimos todo el conocimiento que podamos tener acerca de los parámetros.\n",
    "- $P(X)$ se conoce como **distribución de evidencia** (en inglés *evidence*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué es la (distribución de) evidencia $P(X)$?\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "1. Imaginemos que estamos trabajando con visión por computadora de imágenes de diferentes artistas (por ejemplo Van Gogh,  DaVinci, Monet). ¿Qué es $P(X)$?\n",
    "\n",
    "   **Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Imaginemos que estamos estimando la probabilidad de que un cliente compre en nuestra e-commerce en las siguientes dos semanas (clasificador binario). En este caso:\n",
    "\n",
    "   $$\n",
    "   P(\\theta | X, y) = \\frac{P(y | X, \\theta) P(\\theta | X)}{P(y | X)},\n",
    "   $$\n",
    "\n",
    "   ¿Qué es $P(y | X)$?\n",
    "   \n",
    "   **Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por tanto, modelar la distribución de evidencia es una tarea bastante compleja que en la mayoría de los casos no somos capaces de realizar. \n",
    "\n",
    "Por tanto, en esta clase, estaremos estudiando metodologías analíticas para evitar el cálculo de la distribucion de evicencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Maximum Aposteriori (MAP)\n",
    "\n",
    "En ciertas ocasiones no nos interesa modelar toda la distribución de los parámetros, sino simplemente encontrar el valor *más probable* de los parámetros dadas las observaciones. Esto da lugar al estimador MAP:\n",
    "\n",
    "$$\n",
    "\\theta_{MAP} = \\arg \\max_{\\theta} P(\\theta | X),\n",
    "$$\n",
    "\n",
    "el cual, usando el Teorema de Bayes se puede escribir como:\n",
    "\n",
    "$$\n",
    "\\theta_{MAP} = \\arg \\max_{\\theta} \\frac{P(X | \\theta) P(\\theta)}{P(X)}.\n",
    "$$\n",
    "\n",
    "Sin embargo, como la evidencia $P(X)$ no depende de los parámetros $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta_{MAP} = \\arg \\max_{\\theta} P(X | \\theta) P(\\theta).\n",
    "$$\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/4/49/Emoticon_Face_Smiley_GE.png\" width=\"500px\" height=\"300px\" />\n",
    "\n",
    "De esta manera, observamos que para el cálculo del estimador MAP, evitamos completamente el cálculo de la distribución de evidencia. El problema de estimación resultante lo podemos resolver de manera eficiente usando métodos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y si siempre nos quedamos con el estimador MAP, ¿Cuál es el problema?\n",
    "\n",
    "Si solamente nos quedáramos con el estimador MAP, el enfoque Bayesiano pierde el sentido. Recordamos que bajo el enfoque Bayesiano nos interesa modelar la incertidumbre de los parámetros ante las observaciones que hacemos del mundo, y con un estimador MAP obtenemos los valores **fijos** más probables de los parámetros.\n",
    "\n",
    "Esto tiene varias implicaciones:\n",
    "\n",
    "1. Habíamos dicho que una de las ventajas del enfoque Bayesiano era que nos permitía hacer aprendizaje on-line, solo haciendo los cálculos relativos a cada paso:\n",
    "   \n",
    "   $$\n",
    "   P_k(\\theta) = P(\\theta | x_k) = \\frac{P(x_k | \\theta) P_{k-1}(\\theta)}{P(x_k)}.\n",
    "   $$\n",
    "   \n",
    "   Sin embargo, no podemos usar la estimación MAP como nueva previa en el próximo paso, debido a que sería una función impulso:\n",
    "   \n",
    "   $$\n",
    "   P_{k-1}(\\theta) = \\delta(\\theta - \\theta_{MAP}) = \\left\\{\\begin{array}{cc}\n",
    "   1 & \\text{si } \\theta=\\theta_{MAP} \\\\\n",
    "   0 & \\text{en otro caso}\n",
    "   \\end{array}\\right.,\n",
    "   $$\n",
    "   \n",
    "   y esto no nos aportaría información al siguiente paso:\n",
    "   \n",
    "   $$\n",
    "   P_k(\\theta) = P(\\theta | x_k) = \\frac{P(x_k | \\theta) \\delta(\\theta - \\theta_{MAP})}{P(x_k)} = \\delta(\\theta - \\theta_{MAP}).\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Podríamos caer en un caso donde $\\theta_{MAP}$ sea un valor atípico, y aunque sea el \"más probable\", la mayoría de los datos estén concentrados en otra región. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "# Importar scipy.stats.norm\n",
    "from scipy.stats import norm\n",
    "# Importar numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir VA X, Y\n",
    "X = norm(loc=5, scale=1)\n",
    "Y = norm(loc=8, scale=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma ponderada de densidades\n",
    "x = np.linspace(0, 10, 1000)\n",
    "pdf_Z = 0.8 * X.pdf(x) + 0.2 * Y.pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar densidad de Z\n",
    "plt.plot(x, pdf_Z)\n",
    "plt.xlabel(r'$\\theta$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Si solo estimamos un punto, no podríamos estimar regiones de credibildiad (intervalos de confianza).\n",
    "\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/c/cb/029-sad-but-relieved-face.svg\" width=\"500px\" height=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribuciones conjugadas\n",
    "\n",
    "De manera que los estimadores MAP son bastante útiles en ciertas aplicaciones, pero si queremos aún más flexibilidad en cuanto a la estimación de la distribución de los parámetros, no nos es útil.\n",
    "\n",
    "Si queremos estimar esta distribucion dadas las observaciones debemos buscar otros caminos. Uno de ellos son las **distribuciones conjugadas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recapitulando, la distribución posterior la podemos escribir como:\n",
    "\n",
    "$$\n",
    "P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)},\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- La función de verosimilitud $P(X | \\theta)$ la fija el modelo.\n",
    "- La distribución de evidencia $P(X)$ la fijan los datos.\n",
    "\n",
    "Peeeero, la distribución previa es algo que podemos elegir de acuerdo a **nuestra experiencia, conocimiento previo o simplemente para acomodar los cálculos**.\n",
    "\n",
    "Es decir, podríamos elegir la distribución previa $P(\\theta)$ con el único fin de evitar el cálculo de la la distribución de evidencia $P(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Definición.* (**Previa conjugada**) Decimos que la distribución previa $P(\\theta)$ es conjugada a la función de verosimilitud $P(X | \\theta)$, si la distribución posterior pertenece a la misma familia de distribuciones que la distribución previa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo es esto posible?\n",
    "\n",
    "Supongamos que tenemos dos dos densidades normales distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir VA X, Y\n",
    "# Las definimos arriba\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar densidades\n",
    "plt.plot(x, X.pdf(x), label='densidad X')\n",
    "plt.plot(x, Y.pdf(x), label='densidad Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si multiplicamos estas dos densidades, y renormalizamos para que la integral de $1$, obtenemos de nuevo una distribución normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_pdf(x):\n",
    "    return X.pdf(x) * Y.pdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar densidad de Z\n",
    "plt.plot(x, prod_pdf(x), label='densidad producto')\n",
    "plt.xlim([7, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver cual es el valor de la integral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, sean $X_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$ y $X_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)$. Entonces:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal{N}(x | \\mu_1, \\sigma_1^2) \\mathcal{N}(x | \\mu_2, \\sigma_2^2) & \\propto \\exp\\left\\{-\\frac{(x - \\mu_1)^2}{2 \\sigma_1^2}\\right\\} \\exp\\left\\{-\\frac{(x - \\mu_2)^2}{2 \\sigma_2^2}\\right\\} \\\\\n",
    "& = \\exp\\left\\{-\\frac{(x - \\mu_1)^2}{2 \\sigma_1^2} -\\frac{(x - \\mu_2)^2}{2 \\sigma_2^2} \\right\\} \\\\\n",
    "& = \\exp\\left\\{-\\frac{\\sigma_2^2(x - \\mu_1)^2 + \\sigma_1^2(x - \\mu_2)^2}{2 \\sigma_1^2 \\sigma_2^2}\\right\\} \\\\\n",
    "& = \\exp\\left\\{-\\frac{(x - \\bar{\\mu})^2}{2 \\bar{\\sigma}^2} + const\\right\\} \\\\\n",
    "& \\propto \\exp\\left\\{-\\frac{(x - \\bar{\\mu})^2}{2 \\bar{\\sigma}^2}\\right\\}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo que el producto vuelve a ser (proporcional a) una densidad normal. Ver [el siguiente enlace](https://www.johndcook.com/blog/2012/10/29/product-of-normal-pdfs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base en lo anterior, tomando la posterior:\n",
    "\n",
    "$$\n",
    "P(\\theta | X) = \\frac{P(X | \\theta) P(\\theta)}{P(X)},\n",
    "$$\n",
    "\n",
    "Si la función de verosimilitud $P(X | \\theta) = \\mathcal{N}(X | \\theta, \\sigma^2)$, y la previa se selecciona como:\n",
    "\n",
    "$$\n",
    "P(\\theta) = \\mathcal{N}(\\theta | m, s^2),\n",
    "$$\n",
    "\n",
    "obtenemos:\n",
    "\n",
    "$$\n",
    "P(\\theta | X) = \\mathcal{N}(\\theta | a, b^2).\n",
    "$$\n",
    "\n",
    "Es decir, para una distribución normal sobre los datos con media $\\theta$, la previa conjugada es una distribución normal sobre $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Y qué pasa con la evidencia?\n",
    "\n",
    "Recordemos que la distribución posterior es una distribución **sobre los parámetros**. Debido a que la distribución de evidencia no depende de los parámetros, la podemos pensar como una constante de normalización para que la distribución resultante integre (sume) uno.\n",
    "\n",
    "Esto es una buena noticia, porque operacionalmente, no nos debemos preocupar mucho por las constantes que hacen que la distribución integre a uno. Debemos tener especial cuidado con que **la densidad resultante tenga la misma forma funcional que la previa**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** supongamos que la función de verosimilitud y la distribución previa son:\n",
    "\n",
    "$$\n",
    "p(x | \\theta) = \\mathcal{N}(x |\\theta, 1) \\qquad p(\\theta) = \\mathcal{N}(\\theta |0, 1)\n",
    "$$\n",
    "\n",
    "Encontrar completamente la densidad de probabilidad posterior\n",
    "\n",
    "$$\n",
    "p(\\theta | x) = \\frac{p(x | \\theta) p(\\theta)}{p(x)}.\n",
    "$$\n",
    "\n",
    "<font color=green>En clase ...</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos algunos ejemplos adicionales, pero antes debemos aprender un par de distribuciones más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algunas distribuciones de probabilidad importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Distribución Gamma\n",
    "\n",
    "Es una distribución continua, cuyo soporte son los reales positivos ($x\\in\\mathbb{R}_+$), de dos parámetros $a, b >0$, cuya función de densidad de probabilidad es:\n",
    "\n",
    "$$\n",
    "\\Gamma(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{a - 1} \\exp\\{-b x\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar scipy.stats.gamma\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gamma\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar para diferentes valores de a y b\n",
    "x = np.linspace(0, 5, 100)\n",
    "plt.plot(x, gamma.pdf(x, a=1, scale=1 / 2), label=\"$a=1, b=2$\")\n",
    "plt.plot(x, gamma.pdf(x, a=2, scale=1 / 2), label=\"$a=2, b=2$\")\n",
    "plt.plot(x, gamma.pdf(x, a=3, scale=1 / 2), label=\"$a=3, b=2$\")\n",
    "plt.plot(x, gamma.pdf(x, a=0.5, scale=1 / 1), label=\"$a=0.5, b=1$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $X \\sim \\Gamma(a, b)$, algunos estadísticos importantes son:\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{a}{b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Mode[X] = \\frac{a - 1}{b}, \\quad \\text{para } a > 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var[X] = \\frac{a}{b^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución Gamma es importante porque es la previa conjugada para la **precisión** en una verosimilitud normal.\n",
    "\n",
    "¿Qué es la precisión? Es el recíproco de la varianza. Es decir, la densidad\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left\\{-\\frac{(x - \\mu)^2}{2 \\sigma^2}\\right\\},\n",
    "$$\n",
    "\n",
    "en términos de la precisión $\\gamma = \\frac{1}{\\sigma^2}$ es\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(x | \\mu, \\gamma^{-1}\\right) = \\frac{\\sqrt{\\gamma}}{\\sqrt{2 \\pi}} \\exp\\left\\{-\\gamma\\frac{(x - \\mu)^2}{2}\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es la previa conjugada respecto a la precisión? La respuesta es la distribución Gamma. Veamos\n",
    "\n",
    "$$\n",
    "p(\\gamma | x) = \\frac{p(x | \\gamma) p(\\gamma)}{p(x)} \\propto p(x | \\gamma) p(\\gamma)\n",
    "$$\n",
    "\n",
    "Si la verosimilitud es normal con parámetro la precisión: $p(x | \\gamma) = \\mathcal{N}\\left(x | \\mu, \\frac{1}{\\gamma}\\right) \\propto \\gamma^{1/2} \\exp\\left\\{-\\gamma s\\right\\}$, con $s=\\frac{(x - \\mu)^2}{2}$, y la previa es una distribución gamma: $p(\\gamma) = \\Gamma(\\gamma|a,b) \\propto \\gamma^{a-1} \\exp\\{-b \\gamma\\}$, entonces\n",
    "\n",
    "$$\n",
    "p(\\gamma | x) \\propto \\gamma^{1/2} \\exp\\left\\{-\\gamma s\\right\\} \\gamma^{a-1} \\exp\\{-b \\gamma\\} = \\gamma^{a - 1/2} \\exp\\{-(s+b) \\gamma\\},\n",
    "$$\n",
    "\n",
    "esto es:\n",
    "\n",
    "$$\n",
    "p(\\gamma | x) = \\Gamma(\\gamma|a+1/2,b+s) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Distribución Beta\n",
    "\n",
    "Es una distribución continua, cuyo soporte es el intervalo $[0, 1]$, de dos parámetros $a, b>0$, cuya función de densidad de probabilidad es:\n",
    "\n",
    "$$\n",
    "B(x | a, b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} x^{a - 1} (1 - x)^{b - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar scipy.stats.gamma\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar para diferentes valores de a y b\n",
    "x = np.linspace(0, 1, 100)\n",
    "plt.plot(x, beta.pdf(x, a=0.5, b=0.5), label=\"$a=0.5, b=0.5$\")\n",
    "plt.plot(x, beta.pdf(x, a=1, b=1), label=\"$a=1, b=1$\")\n",
    "plt.plot(x, beta.pdf(x, a=2, b=2), label=\"$a=2, b=2$\")\n",
    "plt.plot(x, beta.pdf(x, a=2, b=5), label=\"$a=2, b=5$\")\n",
    "plt.plot(x, beta.pdf(x, a=10, b=5), label=\"$a=10, b=5$\")\n",
    "plt.plot(x, beta.pdf(x, a=10, b=10), label=\"$a=10, b=10$\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.05, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $X \\sim Beta(a, b)$, algunos estadísticos importantes son:\n",
    "\n",
    "$$\n",
    "E[X] = \\frac{a}{a + b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Mode[X] = \\frac{a - 1}{a + b - 2}, \\quad \\text{para } a > 1, \\text{ y } b > 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "Var[X] = \\frac{ab}{(a + b)^2(a + b - 1)}\n",
    "$$\n",
    "\n",
    "Los parámetros $a$ y $b$ son conocidos como \"pseudo-counts\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución Beta es importante porque es la previa conjugada para la verosimilitud de Bernoulli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Distribución de Bernoulli\n",
    "\n",
    "Supongamos que tenemos el experimento trillado de tirar una moneda al aire, y sabemos que cae cara con probabilidad $\\theta$ y sello con probabilidad $1 - \\theta$.\n",
    "\n",
    "Asignamos la VA $X$ de la siguiente manera:\n",
    "\n",
    "$$\n",
    "X = \\left\\{\\begin{array}{cc}\n",
    "1 & \\text{si cara} \\\\\n",
    "0 & \\text{si sello} \\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Una suposición plausible es que cada tiro de la moneda es independiente.\n",
    "\n",
    "Supongamos que hemos tirado $5$ veces la moneda obteniendo los siguientes datos:\n",
    "\n",
    "$$\n",
    "D = \\{ 1, 1, 0, 1, 0\\}.\n",
    "$$\n",
    "\n",
    "En este sentido, la verosimilitud de los datos es:\n",
    "\n",
    "$$\n",
    "P(D | \\theta) = \\prod_{i=1}^{5} P(X_i | \\theta) = \\theta^{3}(1 - \\theta)^{2}.\n",
    "$$\n",
    "\n",
    "En general, si la moneda cae $N_1$ veces cara y $N_0$ veces sello, la verosimilitud sería:\n",
    "\n",
    "$$\n",
    "P(D | \\theta) = \\theta^{N_1}(1 - \\theta)^{N_0},\n",
    "$$\n",
    "\n",
    "donde $N=N_0+N_1$ es el número total de tiros.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos todo claro, veamos que la distribución Beta es la previa conjugada para la verosimilitud de Bernoulli:\n",
    "\n",
    "$$\n",
    "p(\\theta | X) = \\frac{p(X | \\theta) p(\\theta)}{p(X)} \\propto p(X | \\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "Si la verosimilitud es de Bernoulli con probabilidad $\\theta$: $p(X | \\theta) = \\theta^{N_1}(1 - \\theta)^{N_0}$, y la previa es una distribución Beta: $p(\\theta) = B(\\theta | a, b) \\propto \\theta^{a - 1} (1 - \\theta)^{b - 1}$, entonces\n",
    "\n",
    "$$\n",
    "p(\\theta | X) \\propto \\theta^{N_1}(1 - \\theta)^{N_0} \\theta^{a - 1} (1 - \\theta)^{b - 1} = \\theta^{a + N_1 - 1} (1 - \\theta)^{b + N_0 -1},\n",
    "$$\n",
    "\n",
    "esto es:\n",
    "\n",
    "$$\n",
    "p(\\theta | X) = B(\\theta | a + N_1, b + N_0).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ilustración:**\n",
    "\n",
    "Definimos la variable aleatoria (discreta) binomial:\n",
    "\n",
    "$$\n",
    "X = \\left\\{ \\begin{array}{ccc} 1 & \\text{si} & \\text{la moneda cae cara} \\\\\n",
    "                               0 & \\text{si} & \\text{la moneda cae sello} \\end{array} \\right.\n",
    "$$\n",
    "\n",
    "con función de masa de probabilidad dada por:\n",
    "\n",
    "- $P(X=1) = P(X=1 | \\theta) = \\theta$;\n",
    "- $P(X=0) = P(X=0 | \\theta) = 1 - P(X=1) = 1 - \\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, la función de verosimilitud satisface:\n",
    "\n",
    "$$\n",
    "P(\\mathcal{D} | \\theta) = \\mathcal{L}(\\theta) = \\theta^{N_1} (1 - \\theta)^{N_0}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos de demostrar que la distribución Beta sobre el parámetro $\\theta$ es la previa conjugada:\n",
    "\n",
    "$$\n",
    "P(\\theta) = Beta(\\theta | a, b) \\propto \\theta^{a-1} (1 - \\theta)^{b - 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar beta y bernoulli de scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir VA de bernoulli con parámetro \"real\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular 100 datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimamos la distribución posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de ceros (N0) y número de unos (N1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verosimilitud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos: Previa, verosimilitud, previa * verosimilitud, posterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recibimos datos de otros 100 tiros de la moneda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Para evitar el cálculo de la distribución de evidencia vimos dos posibilidades:\n",
    "\n",
    "1. Estimador MAP:\n",
    "   - Obtenemos el parámetro más probable dada la evidencia.\n",
    "   - No se modela la distribución; obtenemos un valor fijo.\n",
    "   - No se puede usar para aprendizaje on-line.\n",
    "   - Podríamos estimar un valor atípico.\n",
    "   \n",
    "2. Previas conjugadas:\n",
    "   - Seleccionamos la distribución previa para evitar el cálculo de la evidencia.\n",
    "   - Modelamos la distribución posterior.\n",
    "   - Se puede usar para aprendizaje on-line.\n",
    "   - Al selecciónar la previa conjugada con el fin de evitar el cálculo de la evidencia, es posible que esto vaya en contra de la intuición o conocimiento previo que tengamos acerca del problema. No siempre la previa conjugada es adecuada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anuncios\n",
    "\n",
    "1. Tarea 3 para el jueves 6 de octubre\n",
    "2. Quiz la próxima clase (martes 4 de octubre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Esteban Jiménez Rodríguez.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
