{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c5eb35-b06f-4790-87f3-09dbc94a7150",
   "metadata": {},
   "source": [
    "# Multicolinealidad\n",
    "\n",
    "En el tema 9 estuvimos viendo varios problemas que podíamos resolver usando regresión lineal. Por ejemplo:\n",
    "\n",
    "- Nos ayuda a identificar asociaciones falsas.\n",
    "- Nos ayuda a identificar relaciones enmascaradas.\n",
    "\n",
    "Vimos que todo esto lo logramos incluyendo **más predictores** en la regresión, por lo que nos podríamos llevar la **falsa idea** de *agregar todo a la regresión y ver qué pasa*. Desafortunadamente, nuestro modelo no siempre nos dirá que pasa de forma correcta, y es porque le lanzamos preguntas incorrectas.\n",
    "\n",
    "Por eso, en este tema estaremos viendo qué cosas *malas* pueden pasar cuando simplemente añadimos más predictores a nuestra regresión. Veremos tres dificultades:\n",
    "- Multicolinealidad,\n",
    "- Bias de post-tratamiento,\n",
    "- Bias de colisión.\n",
    "\n",
    "> **Objetivos:**\n",
    "> - Entender el problema de multicolinealidad.\n",
    "\n",
    "\n",
    "> **Referencias:**\n",
    "> \n",
    "> - Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2nd edition) - Richard McElreath."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb616c63-8b33-4565-8425-d7fc7cc70783",
   "metadata": {},
   "source": [
    "## 1. Multicolinealidad\n",
    "\n",
    "El caso más común es tener varios predictores para un modelo de regresión. Por ejemplo, en los datos de la leche en diferentes especies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f75def-8979-4ac9-8db3-39521bc77b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b333f09-66d8-4727-9ba4-32b55678f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer milk data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c43a3f-e9ba-49a3-ba96-4c6471b06405",
   "metadata": {},
   "source": [
    "Observamos que para predecir el contenido energético, tenemos siete (7) posibles predictores. ¿Porqué no simplemente incluirlos todos?\n",
    "\n",
    "El primer problema, y quizá el menos nocivo, que nos podemos encontrar es el de **multicolinealidad**. La multicolinealidad significa una asociación fuerte entre dos o más predictores.\n",
    "\n",
    "> En muchos cursos y blogs, probablemente han visto/escuchado hablar de este tema, y es común como estrategia de selección de predictores, descartar variables altamente correlacionadas. Desde nuestro punto de vista, la pura correlación no importa. Lo que importa en realidad es la **asociación**, condicionada a las demás variables en el modelo.\n",
    "\n",
    "La consecuencia de la multicolinealidad es que la distribución posterior nos sugerirá potencialmente que ninguna de las variables colineales se asocia realmente con la variable resultado, **incluso si todas estas variables están fuertemente asociadas con la variable resultado.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a1eaf-1973-43a5-846f-0a32ee368c86",
   "metadata": {},
   "source": [
    "Hablábamos de que este es quizá el problema menos nocivo, porque en realidad no es un problema. Simplemente es un reflejo de como funciona la regresión lineal. En realidad, en presencia de multicolinealidad, nuestro modelo será bueno haciendo predicciones. Lo que nos dará un poco más de dificultades es entender el modelo.\n",
    "\n",
    "Veamos una simple simulación para entender esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa94543-a1a8-4b08-a006-62d74b1782c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar scipy.stats norm & uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d41a5-4f1f-44cc-813c-0946f8b9199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de individuos\n",
    "\n",
    "# Simulación de la altura del individuo ~ N(170, 10)\n",
    "\n",
    "# Simulación de la proporción del tamaño de pierna ~ U(0.4, 0.5)\n",
    "\n",
    "# Simulación de los tamaños de pierna = proporción + error\n",
    "left_leg = leg_proportion * height + norm.rvs(size=n_ind, loc=0, scale=0.005)\n",
    "\n",
    "# Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc6fe7-b2ec-4612-b092-45083c66a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview de los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5bc82f-df7f-4cf6-96af-00733348009e",
   "metadata": {},
   "source": [
    "Estos datos pretenden simular la altura de uan persona y el tamaño de ambas piernas. Se supone que el tamaño de las piernas es proporcional a la altura, pero cada pierna puede ser diferente de la otra por una pequeña cantidad.\n",
    "\n",
    "Ahora, generemos un modelo para intentar predecir la altura usando los tamaños de ambas piernas como predictores. ¿Qué podríamos esperar?\n",
    "\n",
    "- En promedio, la proporción del tamaño de piernas respecto a la altura es del 45% en estos datos simulados.\n",
    "- Por tanto esperaríamos ver los coeficientes de regresión al rededor de $\\frac{170}{170 \\times 0.45} \\approx 2.2$.\n",
    "\n",
    "Veamos que pasa en su lugar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278789d-be61-40e7-b975-ed9c9216d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pymc y arviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69743a43-f7a7-49af-b657-6c1fdfb27d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "with pm.Model() as height_model:\n",
    "    a = pm.Normal(\"a\", mu=1.7, sigma=2)\n",
    "    bleft = pm.Normal(\"bl\", mu=2, sigma=10)\n",
    "    bright = pm.Normal(\"br\", mu=2, sigma=10)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    mu = a + bleft * left_leg + bright * right_leg\n",
    "    height = pm.Normal(\n",
    "        \"height\",\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "        observed=leg_data[\"height\"]\n",
    "    )\n",
    "    idata_multicol = pm.sample(draws=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48037a5-5845-451d-939a-8d434e31fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "az.summary(\n",
    "    idata_multicol,\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    var_names=[\"a\", \"bl\", \"br\", \"sigma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a1e44-9cd7-42c6-b549-13b6c157257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forest\n",
    "az.plot_forest(\n",
    "    idata_multicol,\n",
    "    var_names=[\"a\", \"br\", \"bl\", \"sigma\"],\n",
    "    combined=True,\n",
    "    figsize=[5, 2],\n",
    "    hdi_prob=0.89\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5701b3-0fe5-40d6-a83e-ff58cfead177",
   "metadata": {},
   "source": [
    "Observamos que en la distribución posterior, tanto las medias como las desviaciones estándar no coinciden para nada con nuestra intuición.\n",
    "\n",
    "Incluso, simulando nuevos datos, aunque observemos que los datos son relativamente similares, las posteriores cambian bastante.\n",
    "\n",
    "Esto no quiere decir que nuestro modelo esté fallando. Simplemente, nos está entregando la posterior correspondiente a la pregunta que le hicimos. La pregunta es: *¿Cuál es el valor de conocer cada tamaño de la pierna, si ya conocemos el otro?*\n",
    "\n",
    "Veamos un gráfico de dispersión de puntos de $bl$ vs. $br$, y la densidad de la suma $bl + br$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8d6c9-31b6-452e-9401-13c7214092a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe con muestras de la posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d170c-4659-495b-b2c5-4eaf69406604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114a453-564f-4869-a2bd-8616bbd4debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29be98ed-d14d-4f8d-b62e-69ed000e6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE de suma de posteriores de br y bl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a3f685-a82e-40db-b63e-62ef149a6325",
   "metadata": {},
   "source": [
    "Observamos que la distribución posterior para estos parámetros está altamente **negativamente** correlacionada. Cuando $bl$ es grande, $br$ es pequeña y viceversa.\n",
    "\n",
    "Obviamente, ambas variables contienen casi la misma información, por lo que si las incluimos ambas en un modelo, existirán prácticamente un número infinito de combinaciones de $bl$ y $br$ sobre la línea que vimos hace un momento, que producirán las mismas predicciones.\n",
    "\n",
    "Una manera de entender este hecho, es considerar el caso extremo de incluir exactamente el mismo predictor dos veces:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{array}{ccc}\n",
    "y_i & \\sim & \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "\\mu_i & = & \\alpha + \\beta_1 x_i + \\beta_2 x_i\n",
    "\\end{array}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Observamos que la última línea es equivalente a:\n",
    "\n",
    "$$\n",
    "\\mu_i = \\alpha + (\\beta_1 + \\beta_2) x_i.\n",
    "$$\n",
    "\n",
    "Acá observamos porqué los parámetros $\\beta_1$ y $\\beta_2$ están tan estrechamente correlacionados. Es imposible que uno por separado influencie a $\\mu$; solo su suma, $\\beta_1 + \\beta_2$ puede hacerlo. Podemos ver esto en la densidad que estimamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4de7cf-0c7e-4608-95a9-fa304a748702",
   "metadata": {},
   "source": [
    "Ahora, si ajustamos un modelo con una sola de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5bf5a-00b1-47ce-93ee-4704c2b8b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "with pm.Model() as height_model_left:\n",
    "    a = pm.Normal(\"a\", mu=1.7, sigma=2)\n",
    "    bleft = pm.Normal(\"bl\", mu=2, sigma=10)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "    mu = a + bleft * left_leg\n",
    "    height = pm.Normal(\n",
    "        \"height\",\n",
    "        mu=mu,\n",
    "        sigma=sigma,\n",
    "        observed=leg_data[\"height\"]\n",
    "    )\n",
    "    idata_left = pm.sample(draws=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a88e0-87c5-4a32-8ac7-771d0220ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "az.summary(\n",
    "    idata_left,\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    var_names=[\"a\", \"bl\", \"sigma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa50faf-9e4e-4c4d-98d8-09f38123d705",
   "metadata": {},
   "source": [
    "Observamos que el valor medio de este nuevo $bl$ coincide con el valor medio del $bl+br$ que estimamos en el modelo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16684a3e-11a2-4989-bcae-243b6ec92102",
   "metadata": {},
   "source": [
    "Como conclusión, cuando dos predictores están fuertemente correlacionados, incluir ambos en el modelo puede resultar en confusión. La distribución posterior no va a estar mal, solamente será la respuesta a la pregunta que le hicimos: *¿Cuál es el valor de conocer cada predictor dado que conocemos los demás?*. Cabe decir que el modelo será bueno en cuanto a las predicciones, solamente no podremos interpretar la influencia de cada predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2a41-d796-408d-84b0-6038d7954d40",
   "metadata": {},
   "source": [
    "## 2. Ejemplo con datos reales\n",
    "\n",
    "El ejemplo de las piernas es bastante bueno para entender conceptos, sin embargo, resulta claro que no incluiríamos el tamaño de las dos piernas en un modelo para predecir la altura.\n",
    "\n",
    "En un escenario real, es más complejo anticipar si dos predictores estarán correlacionados. Incluso predictores que en principio no relacionamos mentalmente, podrían inducir un efecto de multicolinealidad. Como vimos, el problema no está en las predicciones en sí, sino en las interpretaciones que hagamos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0ab08-68b0-4a4a-a5ba-d22b034f97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600092e-3ff7-4149-9a91-c6146dc9623c",
   "metadata": {},
   "source": [
    "En este ejemplo, nos concentraremos en los predictores correspondientes a:\n",
    "\n",
    "* porcentaje de grasa\n",
    "* porcentaje de lactosa\n",
    "\n",
    "para modelar el contenido energético de la leche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e53ee9-1bee-4baf-86e2-856f8ef45629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize function\n",
    "def standardize(y: pd.Series) -> pd.Series:\n",
    "    return (y - y.mean()) / y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb21462-5025-4f97-a274-1a7e48a5037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos variables\n",
    "milk_data[\"energy_std\"] = standardize(milk_data[\"kcal.per.g\"])\n",
    "milk_data[\"fat_std\"] = standardize(milk_data[\"perc.fat\"])\n",
    "milk_data[\"lactose_std\"] = standardize(milk_data[\"perc.lactose\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d305de-0527-4960-a59e-e79033e837c6",
   "metadata": {},
   "source": [
    "Comencemos con regresiones bivariadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97458d32-04e4-43dd-adc0-e53d17310f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo con la grasa\n",
    "with pm.Model() as fat_model:\n",
    "    a = pm.Normal(\"a\", 0, 0.2)\n",
    "    bfat = pm.Normal(\"bf\", 0, 0.5)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    mu = a + bfat * milk_data[\"fat_std\"]\n",
    "    k = pm.Normal(\n",
    "        \"energy\",\n",
    "        mu,\n",
    "        sigma,\n",
    "        observed=milk_data[\"energy_std\"]\n",
    "    )\n",
    "    idata_fat = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa50b8f-f3ba-42fe-abc3-a0092a9f8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo con la lactosa\n",
    "with pm.Model() as lactose_model:\n",
    "    a = pm.Normal(\"a\", 0, 0.2)\n",
    "    blac = pm.Normal(\"bl\", 0, 0.5)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    mu = a + blac * milk_data[\"lactose_std\"]\n",
    "    k = pm.Normal(\n",
    "        \"energy\",\n",
    "        mu,\n",
    "        sigma,\n",
    "        observed=milk_data[\"energy_std\"]\n",
    "    )\n",
    "    idata_lactose = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcdc871-ab86-4b0e-8dd1-94431292529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(\n",
    "    idata_fat,\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    var_names=[\"a\", \"bf\", \"sigma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bce8a4-7edb-4e1f-880c-7d517bd72c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(\n",
    "    idata_lactose,\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    var_names=[\"a\", \"bl\", \"sigma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e8d0e-e6e2-4875-b1b0-437c5c95b619",
   "metadata": {},
   "source": [
    "Podemos observar que las posteriores de $bf$ y $bl$ son casi un espejo. Ambas son posteriores estrechas, que yacen de un solo lado del cero, $bf$ en el lado positivo y $bl$ en el lado negativo.\n",
    "\n",
    "Podríamos concluir que ambas variables son predictores \"confiables\" del contenido energético de la leche. Sin embargo, veamos que pasa con un modelo con ambos predictores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf2cca-eee3-4fd8-b375-46fbbf4b34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo con ambas variables\n",
    "with pm.Model() as full_model:\n",
    "    a = pm.Normal(\"a\", 0, 0.2)\n",
    "    bfat = pm.Normal(\"bf\", 0, 0.5)\n",
    "    blac = pm.Normal(\"bl\", 0, 0.5)\n",
    "    sigma = pm.Exponential(\"sigma\", 1)\n",
    "\n",
    "    mu = a + blac * milk_data[\"lactose_std\"] + bfat * milk_data[\"fat_std\"]\n",
    "    k = pm.Normal(\n",
    "        \"energy\",\n",
    "        mu,\n",
    "        sigma,\n",
    "        observed=milk_data[\"energy_std\"]\n",
    "    )\n",
    "    idata_full = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ff57c-726d-4a9f-a39e-734921c44b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "az.summary(\n",
    "    idata_full,\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    var_names=[\"a\", \"bf\", \"bl\", \"sigma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1cdde-327d-49b9-8889-0d3b99daf3d0",
   "metadata": {},
   "source": [
    "Observamos que ahora, las medias de las posteriores de ambos parámetros se movieron hacia cero, e incluso sus desviaciones estándar casi se triplicaron.\n",
    "\n",
    "Esto es un claro indicativo de que tanto el porcentaje de grasa como el porcentaje de lactosa contienen información similar resepecto al contenido energético de la leche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d71fe-271a-4fee-8b1e-346023c43708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcbda1-c8e6-43f6-8da7-fdd4430b7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    milk_data[[\"kcal.per.g\", \"perc.fat\", \"perc.lactose\"]]\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e964e0-ffbb-4899-9463-579b9507a435",
   "metadata": {},
   "source": [
    "Es decir, cualquiera de las dos puede ser un buen predictor para el contenido energético, pero una vez conoces una, incluir la otra en el modelo no es de mucha ayuda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d258bcba-7ed5-4b71-bcf7-c958cf6d1ced",
   "metadata": {},
   "source": [
    "**¿Porqué sucede esto?**\n",
    "\n",
    "Una vez hemos identificado la multicolinealidad, es importante entender qué es lo que la causa. En este ejemplo de la leche, lo que puede estar pasando es que hay un efecto de compensación de una variable con otra.\n",
    "\n",
    "Si una especie amamanta recurrentemente, la leche tiende a ser \"más líquida\" y con menos contenido energético. Dicha leche es alta en azucar (lactosa). Por otra parte, si una especia amamanta de forma más esporádica, la leche necesita ser más alta en energía, para lo cual se necesita más grasa.\n",
    "\n",
    "Esto implica el siguiente modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75a1f8-d4a4-4b3d-b114-cbf100310f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalgraphicalmodels import CausalGraphicalModel\n",
    "from daft import PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2583def-4b6e-47f3-8a31-41a5b32b3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [\"L\", \"D\", \"F\", \"K\"]\n",
    "edges = [(\"D\", \"L\"), (\"D\", \"F\"), (\"L\", \"K\"), (\"F\", \"K\")]\n",
    "dag1 = CausalGraphicalModel(nodes=nodes, edges=edges)\n",
    "pgm1 = PGM()\n",
    "coordinates = {\"L\": (0, 0), \"D\": (1, 0), \"F\": (2, 0), \"K\": (1, 1)}\n",
    "for node in nodes:\n",
    "    pgm1.add_node(node, node, *coordinates[node])\n",
    "for edge in edges:\n",
    "    pgm1.add_edge(*edge)\n",
    "pgm1.render()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34115cfa-06ec-449e-ad6e-f9cc69cb622a",
   "metadata": {},
   "source": [
    "Donde $D$ es una variable no observada que indica qué tan densa debe de ser la leche. Si pudiéramos medir $D$ o tener un modelo para ella, esto sería mejor a intentar diferentes regresiones para ver cuál es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34534c1c-1805-40b7-8795-eb37ad8cbbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (stat-rethink2-pymc_v4)",
   "language": "python",
   "name": "stat-rethink2-pymc_v4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
